{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow_and_keras_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+FMH6kL7873iVcIs0TrvL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rostikmakhanko/handwritten-text-recognition/blob/master/tensorflow_and_keras_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL1JkSUe2Wh3",
        "colab_type": "code",
        "outputId": "86609993-4f92-433c-f6ee-a73c83b7d0ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "#disable low level type of NVIDIA GEFORCE MX130 instructions that this tf is not understanding\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print (\"TensorFlow version: \" + tf.__version__)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=64, activation='relu', input_dim=100))\n",
        "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "sess = tf.compat.v1.Session()\n",
        "\n",
        "print('hello world! it is tensorflow on gpu or not')\n",
        "tf.test.gpu_device_name()\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        "\n",
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 1.15.0\n",
            "hello world! it is tensorflow on gpu or not\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 6062576466158104168\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 8265773087130243478\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 1737200177660408761\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14912199066\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 11899248027602533847\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "25728/60000 [===========>..................] - ETA: 2s - loss: 2.3054 - acc: 0.1108"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-3-05fbca93ba91>\", line 87, in <module>\n",
            "    validation_data=(x_test, y_test))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 727, in fit\n",
            "    use_multiprocessing=use_multiprocessing)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\", line 675, in fit\n",
            "    steps_name='steps_per_epoch')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\", line 394, in model_iteration\n",
            "    batch_outs = f(ins_batch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\", line 3476, in __call__\n",
            "    run_metadata=self.run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/__init__.py\", line 47, in <module>\n",
            "    from tensorflow.contrib import distributions\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/__init__.py\", line 29, in <module>\n",
            "    from tensorflow.contrib.distributions.python.ops import bijectors\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/__init__.py\", line 44, in <module>\n",
            "    from tensorflow.contrib.distributions.python.ops.estimator import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/distributions/python/ops/estimator.py\", line 21, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators.head import _compute_weighted_loss\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/__init__.py\", line 93, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/__init__.py\", line 28, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import *\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/__init__.py\", line 30, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import estimators\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/__init__.py\", line 302, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn.py\", line 34, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 36, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators import estimator\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py\", line 52, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/__init__.py\", line 26, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/dask_io.py\", line 33, in <module>\n",
            "    import dask.dataframe as dd\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/dataframe/__init__.py\", line 2, in <module>\n",
            "    from .core import (\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/dataframe/core.py\", line 52, in <module>\n",
            "    from .accessor import DatetimeAccessor, StringAccessor\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/dask/dataframe/accessor.py\", line 5, in <module>\n",
            "    from ..utils import derived_from\n",
            "  File \"<frozen importlib._bootstrap>\", line 997, in _handle_fromlist\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    }
  ]
}