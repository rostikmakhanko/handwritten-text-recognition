{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thisis_drafts.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNuB6Qq94zIY9AwX1KKPrVe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rostikmakhanko/handwritten-text-recognition/blob/master/thesis/thisis_drafts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ-AzZW-iKPg",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "> First of all lets look on a problem of handwritten text recognition without any particular connections to technologies. In ancient times people used to paint animals or nature signs on the walls of caves to save notifications to other people. Than they realized that better idea is to use some determined list of symbols. ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6coTpu1Sid4z",
        "colab_type": "text"
      },
      "source": [
        "# Thesis roadmap\n",
        "*Based on [Cassie Kozyrkov's 12 Steps to Applied AI](https://medium.com/swlh/12-steps-to-applied-ai-2fdad7fdcdf3)*\n",
        "![alt text](https://miro.medium.com/max/1400/1*DWpwjk-yqNliqQlkqBKfUw.jpeg)\n",
        "0. Reality check(is this problem actually exists, needs and could to be solved).\n",
        "1. Define what is success for my project.\n",
        "2. Get data. Research for exists data sets. Decide how it could be improved.\n",
        "3. Split data into three datasets: training, validation, and test.\n",
        "4. Analyze part of the data with some plots. Make changes based on analysis. Choose algorithms and models.\n",
        "5. Prepare machine learning tools. Transform data to appropriate format.\n",
        "6. Use tools to train models.\n",
        "7. Debug, analyze, and tune prepared data and models. Try to find what's going wrong.\n",
        "8. Validate models(does they works for the data).\n",
        "9. Test the model. The moment where [statistics](https://towardsdatascience.com/statistics-for-people-in-a-hurry-a9613c0ed0b) comes.\n",
        "10. Build a system(UI or API) and integrate models in it. \n",
        "11. Test what was built so far. Launch on servers or build setups.\n",
        "12. Give to users(relatives, friends, teachers).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqJYf31T60lZ",
        "colab_type": "text"
      },
      "source": [
        "# Key terminology\n",
        "\n",
        "\n",
        "\n",
        "> In a nutshell, machine learning is a labeling of things. We get some data on input(it could be nearly anything - numbers, text, photo, sound), and our task to put a label on this data.\n",
        "> Lets start with the task easier than recognition of a large handwriten text - recognition of letters(a, b,..., z). Input is a photo of one of letters and computer needs to provide an output, which letter is on photo. On this example we use these terms:\n",
        "\n",
        "> * **Feature** `x` is an input, photo of a handwritten letter. In a larger machine learning projects could be a lot of different features that marked as `[x_1,x_2,...,x_n]`.\n",
        "> * **Label** `y` is a thing that we are predicting, it could be one of values `['a', 'b',..., 'z']`.\n",
        "> * **Example** is a particular instance of data, `x`. Important that `x` isn't necessarily single value, so talking about `x` we mean multi-dimension vector. In our case `x` is photo, that could be represented as a matrix of pixels. Example could be labeled or unlabeled. Labeled example includes both feature(s) and the label: `{x, y} = {file('letter_r.jpg'), 'r'}`\n",
        "> * **Model** defines relationship between feature and label. It finds correct label for input photo. The proccess of **training** means learining the model this relationship by labeled examples. **Inference** is proccess of applying model to unlabeled data.\n",
        "> * For the example we need to train **classification model** because the task is to answer which letter from set `['a', 'b',..., 'z']` is on a photo, classify input photo.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bx4wqe0TaDL",
        "colab_type": "text"
      },
      "source": [
        "# Training and test sets\n",
        "\n",
        "> After searching dataset it's important to split it into two:\n",
        "> * **Training set** is subset to train a model,\n",
        "> * **Test set** is subset to evaluate success of trained model.\n",
        "\n",
        "> Test set might possibly be 10 times smaller than Training set, but we need to make sure that overall dataset is large enough.\n",
        "\n",
        "> There are two important issues. First is to **randomize dataset** before splitting it into training and test sets. And, second is to **never train a model on test set**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eoz9dtXXH3z0",
        "colab_type": "text"
      },
      "source": [
        "# Building first neural network\n",
        "\n",
        "From [Laurence Moroney's and Josh Gordon's Google IO '18 talk](https://www.youtube.com/watch?v=tjsHSIG8I08)\n",
        "![First neural network](https://lh3.googleusercontent.com/1u9veXnHJIZKGOJkpikzYX3ExmZ9PPlezPPhWzlzF2d8nHzsZ1gqyORWD8zWB0iAa9lQRacs0E7idGPBV5cTIi9HrTC-mcB1NxHxu-tv-L6XVTQSciDhKXzLVvZ4Ar7MOLXkhKsVn1oD6y_aZaY4cLzRSpYUmuJ3g7CT34-QYUipltooOic86ZhstjPATxUKRJAMT-kXsQdX5bQ-WpkqubGCgLzXNq_YtIvoCuJdu9GwwLOTJ-Srk07z1say2cI5PYqjyOIth9eo_kpSaX9UR75Xw3F5lAhZvfllGiahFi-GzNBfI0l63eL_jEvqCz66iaYyLeIvx4kSVxU4B3nSAK8dsoi6v3aXQBV2u_tpYmqPO5uvaYP0vRDXqGGaCquDgvX-B2EsdiWtyd7ajMEGKnr_3muULNiGIa11kr2Xmm6AKOykHELEbCiZSpGNTTsOw-c8pToHw50Dqsf_anSXbGWUyDUMfNJYg76SyLFBmfuJQii-PDhf_lIJqXe8foMumOxz9WTOnGSTdCuRKCyVfSmqvCcj2o6QlrXZLyfFAX5K-hyOaIXlByczptm4GTYhYZRgrMgEEFjbZ2-u7xk5pe8rckXHL3W3QWoo0nbUVx0F_iK-SEPkNxAoypHG6Us4-6O8UC0BuYGQJKddlFuinuz50tFz2aYKptPqqySGR3IuOtlfjJHpngJJxnQLpg=w1280-h709-no)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhP6XlkQnCE4",
        "colab_type": "text"
      },
      "source": [
        "# Stages of product development\n",
        "\n",
        "1.   **Arabic numerals** recognition `['0', '1',..., '9']`([MNIST](http://yann.lecun.com/exdb/mnist/)).\n",
        "2.   **English alphabet letters** recognition `['a', 'b',..., 'z']`.\n",
        "3.   **Client version of 1. or 2.** for browser or mobile.\n",
        "4.   Merge 1. and 2. for **letters and numbers sequences** recognition.\n",
        "5.   **Client version of 4.** for browser or mobile.\n",
        "6.   **Handwritten English words** recognition.\n",
        "7.   Improve **7. with reinforcements** like a set of expected words.\n",
        "8.   **Client version of 7.** for browser or mobile.\n",
        "9.   Recognition of **handwritten English text**.\n",
        "10.  **Client version of 9.** (could work along with some Cloud-based computations).\n",
        "11. *Bonus*: Recognition of **Ukrainian alphabet letters**.\n",
        "\n"
      ]
    }
  ]
}